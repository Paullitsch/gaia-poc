# GAIA â€” Global Artificial Intelligence Architecture

> **Training neural networks without backpropagation â€” in pure Rust.**
> Gradient-free optimization + distributed compute = decentralized AI.

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Phase](https://img.shields.io/badge/Phase-10-brightgreen)]()
[![Worker](https://img.shields.io/badge/Worker-v0.8.5-blue)]()
[![Rust](https://img.shields.io/badge/Pure-Rust%20ðŸ¦€-orange)]()

## ðŸŽ¯ What is GAIA?

GAIA proves that neural networks can be trained **without backpropagation** using evolutionary and gradient-free optimization methods â€” all implemented in **pure Rust**. No Python, no PyTorch, no autograd. Manual forward + backward pass, native environments, and 3-14Ã— faster than Python.

### Key Results (v0.8.5 â€” Pure Rust)

#### LunarLander-v3 â€” SOLVED âœ… (5/6 gradient-free methods!)

| # | Method | Score | Evals | Time | Backprop? |
|---|--------|-------|-------|------|-----------|
| 1 | ðŸ† CMA-ES | **+264.9** | 14.7K | 3.2s | âŒ No |
| 2 | Meta-Learning | **+260.0** | 21K | 4.2s | âŒ No |
| 3 | Curriculum | **+228.0** | 14.7K | 2.9s | âŒ No |
| 4 | Island Model | **+212.8** | 47.5K | 8.3s | âŒ No |
| 5 | Neuromod | **+209.6** | 13K | 2.2s | âŒ No |
| 6 | PPO (baseline) âš¡ | +47.9 | 100K | 37.1s | âœ… Yes |
| 7 | OpenAI-ES | -81.9 | 100K | 11.6s | âŒ No |

> **5 gradient-free methods solve LunarLander. PPO (backpropagation) doesn't.**

#### BipedalWalker-v3 â€” In Progress

| # | Method | Score | Evals | Time | Backprop? |
|---|--------|-------|-------|------|-----------|
| 1 | Neuromod | **+158.2** | 500K | 36min | âŒ No |
| 2 | Meta-Learning | +37.6 | 500K | 3.8min | âŒ No |
| 3 | OpenAI-ES | -1.7 | 500K | 4.8min | âŒ No |
| 4 | CMA-ES | -85.8 | 500K | 5.4min | âŒ No |

> Neuromod leads at +158. 1M eval runs queued. Previously solved with +566 in Phase 8.

### Rust Speedups ðŸ¦€

| Environment | Python | Rust (parallel) | Speedup |
|-------------|--------|-----------------|---------|
| CartPole | 152 evals/s | 2,073 evals/s | **13.6Ã—** |
| LunarLander | ~150 evals/s | solved in 7.1s | **10.4Ã—** |

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          GAIA Server (Rust)          â”‚
â”‚  Job Queue Â· Results Â· Dashboard     â”‚
â”‚        Benchmarks Â· Releases         â”‚
â”‚              :7434                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       P2P Gossip Protocol :7435      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTPS   â”‚          â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”  â”Œâ”€â”€â”€â”´â”€â”€â”  â”Œâ”€â”€â”€â”´â”€â”€â”
    â”‚Worker â”‚  â”‚Workerâ”‚  â”‚Workerâ”‚
    â”‚RTX5070â”‚  â”‚ CPU  â”‚  â”‚Cloud â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
```

**Everything is Rust.** Server, worker, experiments, environments, optimizers â€” zero Python dependency.

- **Server:** Rust/Axum, job orchestration, real-time dashboard, release management
- **Worker:** Rust binary, native experiments, auto-update, 11 methods Ã— 3 environments
- **Environments:** CartPole, LunarLander (Box2D), BipedalWalker (Box2D) â€” native Rust
- **Optimizers:** CMA-ES, OpenAI-ES, PPO (manual backprop) â€” native Rust
- **Protocol:** P2P gossip for decentralized job/model sharing

## ðŸš€ Quick Start

### Run the Server
```bash
docker compose up -d
# Dashboard at http://localhost:7434
```

### Connect a Worker
```bash
./gaia-worker --server https://your-server:7434 --token YOUR_TOKEN --name my-worker --auto-update
```

### Run a Benchmark
```bash
./gaia-worker --bench lunarlander    # CMA-ES on LunarLander
./gaia-worker --bench cartpole       # CMA-ES on CartPole
```

### Submit an Experiment
```bash
curl -X POST http://localhost:7434/api/jobs/submit \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"method": "cma_es", "environment": "LunarLander-v3", "max_evals": 100000, "params": {"sigma0": 0.5, "patience": 200}}'
```

## ðŸ“Š Research Phases

| Phase | Focus | Result |
|-------|-------|--------|
| 1-2 | Pure Evolution | âœ… CartPole, âŒ LunarLander |
| 3 | Forward-Forward | ðŸŸ¡ 50-70% of backprop |
| 4 | Meta-Plasticity | ðŸŸ¡ Beats naive backprop |
| 5 | Neuromodulation | ðŸŸ¡ +80.0 breakthrough |
| 6 | PPO Baseline | ðŸŸ¡ PPO: +264.8 (reference) |
| 7 | **CMA-ES + Compute** | **âœ… LunarLander SOLVED** |
| 8 | **BipedalWalker** | **âœ… BipedalWalker SOLVED (+566)** |
| 9 | **Decentralization** | âœ… Island Model, P2P Gossip |
| 10 | **Rust + Meta-Learning** | ðŸ”¬ Pure Rust, scaling tests, learning rule evolution |

## ðŸ§¬ Methods (11 native Rust)

| Method | Type | Key Idea |
|--------|------|----------|
| `cma_es` | Evolutionary | CMA-ES with patience + restart |
| `openai_es` | Evolutionary | Antithetic sampling + weight decay |
| `curriculum` | Evolutionary | Reward shaping + difficulty ramp |
| `neuromod` | Neuroevolution | CMA-ES + neuromodulatory plasticity |
| `island_model` | Distributed | 4 CMA-ES populations + migration |
| `island_advanced` | Distributed | 6 heterogeneous islands |
| `neuromod_island` | Hybrid | Neuromod + Island Model |
| `meta_learning` | Meta | Evolve weights + learning rules |
| `meta_learning_pure` | Meta | Evolve ONLY learning rules (21 params) |
| `scaling_test` | Experiment | CMA-ES at 1K-500K params |
| `ppo_baseline` | Backprop âš¡ | PPO with manual backprop (control group) |

## ðŸŽ® Environments (3 native Rust)

| Environment | Obs | Actions | Solved | Rust? |
|-------------|-----|---------|--------|-------|
| CartPole-v1 | 4D | Discrete(2) | â‰¥475 | âœ… |
| LunarLander-v3 | 8D | Discrete(4) | â‰¥200 | âœ… |
| BipedalWalker-v3 | 24D | Continuous(4) | â‰¥300 | âœ… |

## ðŸ§  Singularity Roadmap

| Stage | Goal | Status |
|-------|------|--------|
| 1 | Find scaling law (where does CMA-ES break?) | ðŸ”¬ Testing |
| 2 | Hierarchical optimization (ES evolves learning rules) | ðŸ”¬ Testing |
| 3 | Decentralized emergence (gossip + local rules) | â³ Planned |
| 4 | Open question: can local rules + evolution = intelligence? | â“ |

## ðŸ“ Whitepapers

- [GAIA v6](GAIA_v6_WhitePaper.md) â€” 60+ experiments, sample efficiency analysis
- [GAIA v5](GAIA_v5_WhitePaper.md) â€” Island Model, P2P Protocol
- [GAIA v4](GAIA_v4_WhitePaper.md) â€” Phase 7 breakthrough
- [Earlier](GAIA_v3_WhitePaper.md) â€” v2, v3

## ðŸ§  Core Thesis

> *Gradient-free optimization is not inferior to backpropagation â€” it's more compute-intensive but inherently parallelizable, decentralizable, and biologically plausible. With meta-learning (evolving learning rules instead of weights), it scales to arbitrary network sizes.*

## License

MIT â€” see [LICENSE](LICENSE)
