# Epistemische Architektur

GAIA verpflichtet sich zu radikaler epistemischer Ehrlichkeit. Jede Aussage wird einer Sicherheitsebene zugeordnet.

## Die vier Ebenen

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ebene 4: Spekulative Visionen  (<25%)   â”‚
â”‚  "Dezentrales GAIA-Netzwerk"             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Ebene 3: Hypothesen  (25-75%)           â”‚
â”‚  "Skaliert auf Atari"                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Ebene 2: Empirisch gesichert  (>90%)    â”‚
â”‚  "CMA-ES lÃ¶st LunarLander"              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Ebene 1: Axiomatisch  (~100%)           â”‚
â”‚  "No-Free-Lunch, Informationstheorie"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Aktuelle Einordnung (v4)

### Ebene 2: Empirisch gesichert âœ…

| Aussage | Evidenz |
|---------|---------|
| Evolution skaliert nicht fÃ¼r Gewichte >7K Parameter | Phase 1-2, reproduzierbar |
| Forward-Forward erreicht 50-70% von Backprop | Phase 3 |
| Meta-PlastizitÃ¤t schlÃ¤gt naive Backprop | Phase 4, reproduziert in Phase 5 |
| Neuromodulation verbessert lokales Lernen | Phase 5 (+80.0) |
| **CMA-ES lÃ¶st LunarLander (+235.3)** | **Phase 7, neu** |
| **Curriculum + CMA-ES erreicht +274** | **Phase 7, neu** |
| **OpenAI-ES lÃ¶st LunarLander (+206.6)** | **Phase 7, neu** |
| **Verteilte Infrastruktur funktioniert** | **Phase 7, neu** |
| Compute ist der entscheidende Faktor | Phase 7 (2Kâ†’100K = -43â†’+274) |

### Ebene 3: Theoretische Hypothesen ğŸ”¬

| Aussage | EinschÃ¤tzung |
|---------|-------------|
| GAIA skaliert auf BipedalWalker | Plausibel, CMA-ES sollte funktionieren |
| CMA-ES degradiert ab ~10K Parameter | Theoretisch begrÃ¼ndet (O(nÂ²)) |
| Multi-Worker beschleunigt proportional | Architektur steht, ungetestet |
| Neuromod kann CMA-ES schlagen bei gleichem Compute | Offen |

### Ebene 4: Spekulativ ğŸŒŸ

| Aussage | EinschÃ¤tzung |
|---------|-------------|
| Dezentrales GAIA-Netzwerk mit 1000+ Knoten | Konzeptuell, keine Evidenz |
| GAIA lÃ¶st Atari-Spiele | MÃ¶glich, braucht massive GPU |
| Demokratisiertes KI-Training | Langfristvision |

## Prinzipien

1. **Negative Ergebnisse publizieren:** Phase 1-2 (Evolution versagt) sind genauso wichtig wie Phase 7 (Durchbruch)
2. **Hypothesen revidieren:** v1â†’v2â†’v3â†’v4 zeigt den wissenschaftlichen Prozess
3. **Limitierungen benennen:** Nur 1 Benchmark, keine statistische Signifikanz, GPU nicht ausgelastet
4. **Kein Hype:** +274 auf LunarLander ist kein AGI. Es ist ein Proof-of-Concept.
