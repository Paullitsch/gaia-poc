# Scaling-Hypothesen

## Die zentrale Frage

Phase 7 bewies: gradientenfreie Methoden lÃ¶sen LunarLander. Aber **wo liegen die Grenzen?**

## Dimension 1: Parameterzahl

CMA-ES hat O(nÂ²) Speicher- und Compute-KomplexitÃ¤t fÃ¼r die Kovarianzmatrix.

| Parameter | CMA-ES Kovarianzmatrix | SchÃ¤tzung |
|-----------|----------------------|-----------|
| 2.788 | 7.8 M EintrÃ¤ge | âœ… Funktioniert |
| 10.000 | 100 M EintrÃ¤ge | ğŸŸ¡ Grenzbereich |
| 50.000 | 2.5 G EintrÃ¤ge | âŒ Zu groÃŸ |
| 100.000 | 10 G EintrÃ¤ge | âŒ UnmÃ¶glich |

**LÃ¶sung fÃ¼r groÃŸe Netzwerke:** Diagonal CMA-ES (sep-CMA-ES) oder OpenAI-ES (O(n)).

**Hypothese:** CMA-ES dominiert bis ~10K Parameter, danach OpenAI-ES.

## Dimension 2: Umgebungs-KomplexitÃ¤t

| Umgebung | Obs | Act | Schwierigkeit | GeschÃ¤tzte Evals |
|----------|-----|-----|--------------|------------------|
| CartPole | 4 | 2 | Trivial | ~5K |
| LunarLander | 8 | 4 | Mittel | ~100K |
| BipedalWalker | 24 | 4 (cont.) | Schwer | ~500K |
| Atari (Pong) | 210Ã—160Ã—3 | 6 | Sehr schwer | ~5M |
| MuJoCo (Humanoid) | 376 | 17 | Extrem | ~50M |

**Hypothese:** Gradientenfreie Methoden skalieren bis BipedalWalker. Atari erfordert CNN â†’ groÃŸe Netzwerke â†’ nur mit OpenAI-ES + massivem Compute.

## Dimension 3: Compute-Skalierung

Phase 7 zeigte sublineares Scaling:

```
Score
+280 â”¤                          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+240 â”¤                     â—â”€â”€/
+200 â”¤â”€ â”€ â”€ â”€ SOLVED â”€ â”€/â”€ â”€ â”€ â”€ â”€ â”€ â”€
+160 â”¤              â— /
+120 â”¤           â—/
 +80 â”¤        â—/
  +0 â”¤     â—/
 -50 â”¤  â—/
-100 â”¤â—
     â””â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€
      2K 10K 20K 40K 60K 80K 100K
              Evaluierungen
```

**Beobachtung:** Abnehmende Returns nach ~50K Evals. Mehr Compute hilft, aber der Marginalnutzen sinkt.

## Dimension 4: Multi-Worker-Parallelisierung

### Theoretisch
Population-Evaluation ist trivial parallel. N Workers â†’ NÃ— Speedup.

### Praktisch
- Kommunikations-Overhead (Ergebnisse streamen)
- Server wird Bottleneck bei >100 Workers
- CMA-ES `tell()` ist sequentiell (sammelt alle Fitness-Werte)

**Hypothese:** >0.7x linearer Speedup bis ~8 Workers, danach Overhead.

### Island-Modell (Future)
FÃ¼r >8 Workers: unabhÃ¤ngige CMA-ES-Instanzen pro Worker, periodische Migration der besten Individuen. Voll dezentral, kein zentraler Bottleneck.

## Dimension 5: Methoden-Vergleich bei Skala

| Methode | Kleine Netze (<5K) | Mittlere (5-50K) | GroÃŸe (>50K) |
|---------|-------------------|-------------------|-------------|
| CMA-ES | ğŸ† Dominant | ğŸŸ¡ Degradiert | âŒ Zu teuer |
| OpenAI-ES | ğŸŸ¡ Okay | ğŸ† Dominant | ğŸŸ¡ Machbar |
| Neuromod | ğŸŸ¡ Vielversprechend | â“ Ungetestet | â“ Ungetestet |
| GA | âŒ Schlecht | âŒ Schlecht | âŒ Schlecht |

## Empirische Ergebnisse (NEU)

### LunarLander Scaling â†’ Kein Breakpoint!

| Params | CMA-ES Score | Modus |
|--------|-------------|-------|
| 1.000 | +215.1 | Full Covariance |
| 10.000 | +227.2 | Diagonal |
| 33.000 | +204.5 | Diagonal |
| 100.000 | +225.0 | Diagonal |

**Ergebnis:** Alle NetzgrÃ¶ÃŸen lÃ¶sen LunarLander. Das Problem ist zu einfach fÃ¼r einen Breakpoint. Die Hypothese "CMA-ES degradiert ab ~10K" stimmt bei LunarLander **nicht** â€” Diagonal-Modus kompensiert.

### NÃ¤chster Schritt: BipedalWalker Scaling

BipedalWalker ist hÃ¤rter (24D obs, 4D continuous action, ~300 threshold). Scaling-Tests mit 1K, 10K, 33K, 100K Params laufen. Hier erwarten wir den Breakpoint.

### Meta-Learning als SkalierungslÃ¶sung

Statt grÃ¶ÃŸere Netze direkt zu evolvieren â†’ **evolve Lernregeln** (21 Parameter), die beliebig groÃŸe Netze trainieren. Siehe [[Meta-Learning]].

## Offene Fragen

1. **Wo liegt der BipedalWalker Breakpoint?** â€” Scaling-Tests laufen
2. **KÃ¶nnen 21 Lernregel-Parameter beliebig groÃŸe Netze trainieren?** â€” Pure Meta-Learning Tests laufen
3. **Gibt es einen Crossover-Punkt** wo gradientenfreie Methoden effizienter als Backprop werden?
4. **Skaliert das Island-Modell** auf 100+ heterogene Knoten?
5. **Transferieren Lernregeln zwischen Environments?**
